=============================================================================
== SPINDLE: Scalable Parallel Input Network for Dynamic Load Environments  ==
=============================================================================
Authors:    SPINDLE:              W.Frings <W.Frings at fz-juelich dot de>
                                  Matthew LeGendre (legendre1 at llnl dot gov)
            COBO:                 Adam Moody <moody20 at llnl dot gov>

Version:    0.6 (May 2013)

Introduction:
============

Dynamic linking and loading are widely used in High Performance
Computing (HPC). As HPC applications are becoming increasingly
complex, developers leverage these techniques that are well-suited for
large-scale software development through support for modularization
and computational steering. But the growing trend towards high numbers
of dynamically linked libraries (DLLs) within applications poses
greater challenges to application start-up. During start-up at scale,
a large number of processes simultaneously access many DLLs, which
creates file access storms that overwhelm shared file systems and acts
like site-wide denial-of-service attacks. 

The Scalable Parallel Input Network for Dynamic Loading Environment
(SPINDLE) presents a novel approach that provides a scalable and
transparent dynamic linking and loading environment. SPINDLE extends
the stock dynamic loader (e.g., ld.so) with a scalable file cache
server overlay network. The network forms a forest topology that
allows SPINDLE to use a varying number of communication trees in the
forest, thereby only the roots of the trees perform file operations of
dynamic loading and scalably propagate the results to all other cache
servers. The cached results are then used by SPINDLE clients that
intercept and re-route file operations of the dynamic
loaders. Building on the existing loader auditing interface, system
requires no modifications to either the loader or the application.

Scalability:
------------

Preliminary results on LLNL Linux clusters indicate that SPINDLE
prototype improves the performance of Pynamic, a benchmark that
stresses the dynamic loading system, by a factor of 3.5 over the
traditional approach at 768 MPI processes, the scale at which we could
run the traditional scheme without significantly affecting other
jobs. Further this benchmark under SPINDLE support scales well on LLNL
clusters without pounding on the shared resources up to 8400
processes.


Directories:
============

./lib              --> low level communication layers (socket, pipe, shmem)
./cache            --> Internal data structure for file meta data (cache)
./auditclient      --> Implementation of Loader Auditing Interface for SPINDLE,
                       Sample client applications
./auditserver      --> Implementation of SPINDLE server,
                       High level communication layer (cobo, msocket)
./simulator        --> MPI-programm starting all components of SPINDLE in one 
                       MPI context
./launchmon        --> LaunchMON start-up command and BE-server
./client           --> client part of simple program to test low-level communication
./server           --> server part of simple program to test low-level communication
./tools/cobo/src   --> cobo src used by one of the high level SPINDLE comm. layers      
./tools/cobo/test  --> rsh start-up utility
./tools/slurm      --> utility scripts for LLNL cluster running SLURM,
                       benchmarking scripts for pynamic
./tools/sion_debug --> Implements DPRINTF interface for selective printf-debugging
                       from SIONlib package


Compilation:
============

1) Make a build directory, and run spindle/configure from that directory.

2) make install from the build directory

Usage:
======

spindle <job launch command>

 e.g,

spindle mpirun -n 128 mpi_hello_world

